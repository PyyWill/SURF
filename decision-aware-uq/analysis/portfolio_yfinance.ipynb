{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn.objects as so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_quantile(fmt_str):\n",
    "    dfs = []\n",
    "    for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "        df = pd.read_csv(fmt_str.format(alpha=alpha))\n",
    "        df['alpha'] = alpha\n",
    "        dfs.append(df)\n",
    "    df = pd.concat(dfs).reset_index(drop=True)\n",
    "\n",
    "    best_lr, best_l2reg = df.groupby(['lr', 'l2reg'])['loss'].mean().idxmin()\n",
    "    print(f'best lr: {best_lr:.3g}, best l2reg: {best_l2reg:.3g}')\n",
    "\n",
    "    df['lr_str'] = df['lr'].map(lambda x: f'{x:.1g}')\n",
    "    p = (\n",
    "        so.Plot(df, x='lr_str', y='loss', color='l2reg')\n",
    "        .add(so.Dots(), so.Dodge())\n",
    "        .add(so.Dot(), so.Agg(), so.Dodge())\n",
    "        .add(so.Range(), so.Est(errorbar='sd'), so.Dodge())\n",
    "        .facet('alpha', wrap=2)\n",
    "        .layout(size=(10, 10))\n",
    "    )\n",
    "    display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hyperparams_quantile('portfolio_yf_quantile/hyperparams_a{alpha:.2g}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hyperparams_quantile('portfolio_yf_quantile_shuffled/hyperparams_a{alpha:.2g}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperparams_gaussian(csv_path, ylim=(None, None)):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['is_nan'] = df['loss'].isna().astype(int)\n",
    "    with pd.option_context('display.float_format', '{:.4g}'.format):\n",
    "        display(df.groupby(['lr', 'l2reg']).agg({'loss': ['mean', 'std'], 'is_nan': 'sum'}))\n",
    "\n",
    "    best_lr, best_l2reg = df.groupby(['lr', 'l2reg'])['loss'].mean().idxmin()\n",
    "    print(f'best lr: {best_lr:.3g}, best l2reg: {best_l2reg:.3g}')\n",
    "\n",
    "    df['lr_str'] = df['lr'].map(lambda x: f'{x:.1g}')\n",
    "    p = (\n",
    "        so.Plot(df, x='lr_str', y='loss', color='l2reg')\n",
    "        .add(so.Dots(), so.Dodge())\n",
    "        .add(so.Dot(), so.Agg(), so.Dodge())\n",
    "        .add(so.Range(), so.Est(errorbar='sd'), so.Dodge())\n",
    "        .layout(size=(5, 5))\n",
    "        .limit(y=ylim)\n",
    "    )\n",
    "    display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hyperparams_gaussian('portfolio_yf_gaussian/hyperparams.csv', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_hyperparams_gaussian('portfolio_yf_gaussian_shuffled/hyperparams.csv', ylim=(0, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETO vs. E2E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_eto_vs_e2e(long_df, num_rows):\n",
    "    return (\n",
    "        so.Plot(long_df, x='alpha', y='value', color='model')\n",
    "        .facet(row='metric', col='split')\n",
    "        .add(so.Dots(), so.Dodge(), so.Jitter(.5))\n",
    "        .share(y='row')\n",
    "        .scale(x=so.Nominal())\n",
    "        .layout(size=(10, num_rows * 3))\n",
    "    )\n",
    "\n",
    "def print_eto_e2e_results(df):\n",
    "    best_e2e_models = (\n",
    "        df[~df['val_task_loss'].isna()].groupby(['alpha', 'model'])['val_task_loss']\n",
    "        .mean().unstack().idxmin(axis=1)\n",
    "    )\n",
    "\n",
    "    e2e_results_dict = {}\n",
    "    for alpha in best_e2e_models.index:\n",
    "        model = best_e2e_models.loc[alpha]\n",
    "        mask = (df['alpha'] == alpha) & (df['model'] == model)\n",
    "        new_df = df.loc[mask, ['test_task_loss', 'test_coverage']].agg(['mean', 'std'])\n",
    "        e2e_results_dict[alpha] = new_df.unstack()\n",
    "    best_e2e = pd.DataFrame(e2e_results_dict).T\n",
    "    print('E2E results:')\n",
    "    display(best_e2e)\n",
    "\n",
    "    eto_results = (\n",
    "        df.loc[df['model'] == 'eto']\n",
    "        .groupby('alpha')[['test_task_loss', 'test_coverage']]\n",
    "        .agg(['mean', 'std'])\n",
    "    )\n",
    "    print('ETO results:')\n",
    "    display(eto_results)\n",
    "    return\n",
    "\n",
    "def get_df(eto_fmt_str, eto_cols, e2e_fmt_str, e2e_cols):\n",
    "    dfs = []\n",
    "    for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "        try:\n",
    "            df_eto = pd.read_csv(eto_fmt_str.format(alpha=alpha))\n",
    "            df_eto['model'] = 'eto'\n",
    "            df_eto['alpha'] = alpha\n",
    "            dfs.append(df_eto[eto_cols])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for lr in [0.0316, 1e-3, 1e-4, 1e-5]:\n",
    "            try:\n",
    "                df_e2e = pd.read_csv(e2e_fmt_str.format(alpha=alpha, lr=lr))\n",
    "                df_e2e['model'] = f'e2e_lr{lr:.3g}'\n",
    "                df_e2e['alpha'] = alpha\n",
    "                dfs.append(df_e2e[e2e_cols])\n",
    "            except FileNotFoundError as e:\n",
    "                print(e)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "def convert_to_long_df(df):\n",
    "    long_df = df.melt(id_vars=['model', 'alpha', 'seed'], var_name='metric', value_name='value')\n",
    "    long_df['split'] = long_df['metric'].map(lambda x: x.split('_')[0])\n",
    "    long_df['metric'] = long_df['metric'].map(lambda x: x.split('_', maxsplit=1)[1])\n",
    "    return long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'model', 'alpha', 'seed',\n",
    "    'train_pinball_loss', 'train_task_loss',\n",
    "    'train_coverage', 'train_coverage_no_conformal',\n",
    "    'test_pinball_loss', 'test_task_loss',\n",
    "    'test_coverage', 'test_coverage_no_conformal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(\n",
    "    eto_fmt_str='portfolio_yf_quantile/eto_a{alpha:.2f}_lr0.0316_reg0.001.csv',\n",
    "    eto_cols=cols,\n",
    "    e2e_fmt_str='portfolio_yf_quantile/e2e_finetune_a{alpha:.2f}_lr{lr:.3g}_reg0.001.csv',\n",
    "    e2e_cols=cols + ['val_task_loss']\n",
    ")\n",
    "print_eto_e2e_results(df)\n",
    "long_df = convert_to_long_df(df.drop('val_task_loss', axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(\n",
    "    eto_fmt_str='portfolio_yf_quantile_shuffled/eto_a{alpha:.2f}_lr0.0316_reg0.0001.csv',\n",
    "    eto_cols=cols,\n",
    "    e2e_fmt_str='portfolio_yf_quantile_shuffled/e2e_finetune_a{alpha:.2f}_lr{lr:.3g}_reg0.0001.csv',\n",
    "    e2e_cols=cols + ['val_task_loss']\n",
    ")\n",
    "print_eto_e2e_results(df)\n",
    "long_df = convert_to_long_df(df.drop('val_task_loss', axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'model', 'alpha', 'seed',\n",
    "    'train_nll_loss', 'train_task_loss',\n",
    "    'train_coverage', 'train_coverage_no_conformal',\n",
    "    'test_nll_loss', 'test_task_loss',\n",
    "    'test_coverage', 'test_coverage_no_conformal'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best lr: 0.001, best l2reg: 0.001\n",
    "\n",
    "df = get_df(\n",
    "    eto_fmt_str='portfolio_yf_gaussian/eto_a{alpha:.2f}_lr0.001_reg0.001.csv',\n",
    "    eto_cols=cols,\n",
    "    e2e_fmt_str='portfolio_yf_gaussian/e2e_finetune_a{alpha:.2f}_lr{lr:.3g}_reg0.001.csv',\n",
    "    e2e_cols=cols + ['val_task_loss']\n",
    ")\n",
    "print_eto_e2e_results(df)\n",
    "long_df = convert_to_long_df(df.drop('val_task_loss', axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_df(\n",
    "    eto_fmt_str='portfolio_yf_gaussian_shuffled/eto_a{alpha:.2f}_lr0.001_reg0.csv',\n",
    "    eto_cols=cols,\n",
    "    e2e_fmt_str='portfolio_yf_gaussian_shuffled/e2e_finetune_a{alpha:.2f}_lr{lr:.3g}_reg0.csv',\n",
    "    e2e_cols=cols + ['val_task_loss']\n",
    ")\n",
    "print_eto_e2e_results(df)\n",
    "long_df = convert_to_long_df(df.drop('val_task_loss', axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PICNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_picnn_eto_df(eto_fmt_str, eto_cols):\n",
    "    dfs = []\n",
    "    for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for lr in [1e-3, 1e-4]:\n",
    "            for l2reg in [1e-3, 1e-4]:\n",
    "                try:\n",
    "                    df_eto = pd.read_csv(eto_fmt_str.format(alpha=alpha, lr=lr, l2reg=l2reg))\n",
    "                    df_eto['lr'] = lr\n",
    "                    df_eto['l2reg'] = l2reg\n",
    "                    df_eto['model'] = f'eto_lr{lr:.3g}_reg{l2reg:.3g}'\n",
    "                    df_eto['alpha'] = alpha\n",
    "                    dfs.append(df_eto[eto_cols])\n",
    "                except FileNotFoundError as e:\n",
    "                    print(e)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "def get_picnn_e2e_df(e2e_fmt_str, e2e_cols):\n",
    "    dfs = []\n",
    "    for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "        for lr in [1e-2, 1e-3, 1e-4]:\n",
    "            for l2reg in [1e-3, 1e-4]:\n",
    "                try:\n",
    "                    df_eto = pd.read_csv(e2e_fmt_str.format(alpha=alpha, lr=lr, l2reg=l2reg))\n",
    "                    df_eto['lr'] = lr\n",
    "                    df_eto['l2reg'] = l2reg\n",
    "                    df_eto['model'] = f'e2e_lr{lr:.3g}_reg{l2reg:.3g}'\n",
    "                    df_eto['alpha'] = alpha\n",
    "                    dfs.append(df_eto[e2e_cols])\n",
    "                except FileNotFoundError as e:\n",
    "                    print(e)\n",
    "\n",
    "    df = pd.concat(dfs)\n",
    "    return df\n",
    "\n",
    "def print_picnn_results(df, by_col):\n",
    "    results_dict = {}\n",
    "    best_hyps = (\n",
    "        df.groupby(['alpha', 'lr', 'l2reg'])[by_col]\n",
    "        .mean()\n",
    "        .unstack('alpha')\n",
    "        .idxmin(axis=0)\n",
    "    )\n",
    "    for alpha in best_hyps.index:\n",
    "        lr, l2reg = best_hyps.loc[alpha]\n",
    "        mask = (df['alpha'] == alpha) & (df['lr'] == lr) & (df['l2reg'] == l2reg)\n",
    "        new_df = df.loc[mask, ['test_task_loss', 'test_coverage']].agg(['mean', 'std'])\n",
    "        results_dict[alpha] = new_df.unstack()\n",
    "    best_results = pd.DataFrame(results_dict).T\n",
    "    display(best_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'model', 'alpha', 'seed', 'lr', 'l2reg',\n",
    "    'train_task_loss', 'train_coverage',\n",
    "    'test_task_loss', 'test_coverage',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_picnn_eto_df(\n",
    "    eto_fmt_str='portfolio_yf_picnn_shuffle/eto_a{alpha:.2f}_L2_d64_lr{lr:.3g}_reg{l2reg:.3g}.csv',\n",
    "    eto_cols=cols\n",
    ")\n",
    "print_picnn_results(df, by_col='train_task_loss')\n",
    "long_df = convert_to_long_df(df.drop(['lr', 'l2reg'], axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.groupby(['alpha', 'lr', 'l2reg']).agg({'train_task_loss': ['mean', 'std', 'count']}))\n",
    "\n",
    "for alpha in [0.01, 0.05, 0.1, 0.2]:\n",
    "    best_lr, best_l2reg = df[df['alpha'] == alpha].groupby(['lr', 'l2reg'])['train_task_loss'].mean().idxmin()\n",
    "    print(f'alpha {alpha}: lr = {best_lr:.3g}, l2reg = {best_l2reg:.3g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_picnn_e2e_df(\n",
    "    e2e_fmt_str='portfolio_yf_picnn_shuffle/e2e_finetune_a{alpha:.2f}_L2_d64_lr{lr:.3g}_reg{l2reg:.3g}.csv',\n",
    "    e2e_cols=cols + ['val_task_loss']\n",
    ")\n",
    "print_picnn_results(df, by_col='val_task_loss')\n",
    "long_df = convert_to_long_df(df.drop(['val_task_loss', 'lr', 'l2reg'], axis=1))\n",
    "plot_eto_vs_e2e(long_df, num_rows=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dauq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
