{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Collection\n",
    "from typing import Any, Self\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats\n",
    "\n",
    "from portfolio import synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMM:\n",
    "    def __init__(self, means, covs, ps: Collection[float], x_slice=None, y_slice=None):\n",
    "        self.K = len(ps)\n",
    "        self.d = means[0].shape[0]\n",
    "        self.x_slice = x_slice\n",
    "        self.y_slice = y_slice\n",
    "\n",
    "        assert len(means) == self.K\n",
    "        assert len(covs) == self.K\n",
    "        for k in range(self.K):\n",
    "            assert means[k].shape[0] == self.d\n",
    "            assert covs[k].shape == (self.d, self.d)\n",
    "\n",
    "        self.ps = np.asarray(ps)\n",
    "        self.dists = [\n",
    "            scipy.stats.multivariate_normal(mean=mean, cov=cov)\n",
    "            for mean, cov in zip(means, covs)\n",
    "        ]\n",
    "        self.rng = np.random.default_rng()\n",
    "\n",
    "        if x_slice is not None and y_slice is not None:\n",
    "            self.dists_x = [\n",
    "                scipy.stats.multivariate_normal(\n",
    "                    mean=mean[x_slice], cov=cov[x_slice, x_slice])\n",
    "                for mean, cov in zip(means, covs)\n",
    "            ]\n",
    "            self.dists_y = [\n",
    "                scipy.stats.multivariate_normal(\n",
    "                    mean=mean[y_slice], cov=cov[y_slice, y_slice])\n",
    "                for mean, cov in zip(means, covs)\n",
    "            ]\n",
    "\n",
    "    def sample(self, size: int = 1) -> np.ndarray:\n",
    "        if size == 1:\n",
    "            k = self.rng.choice(len(self.ps), p=self.ps)\n",
    "            return self.dists[k].rvs()\n",
    "        else:\n",
    "            comps = self.rng.choice(len(self.ps), p=self.ps, size=size)\n",
    "            return np.stack([self.dists[k].rvs() for k in comps])\n",
    "\n",
    "    def pdf(self, z: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            z: (d,) or (n, d) array of points to evaluate the pdf at\n",
    "        \"\"\"\n",
    "        return sum(p * d.pdf(z) for p, d in zip(self.ps, self.dists))\n",
    "\n",
    "    def cond_on_x(self, x: np.ndarray) -> Self:\n",
    "        \"\"\"Return the conditional distribution p(y|x).\n",
    "\n",
    "        The conditional distribution itself is a GMM:\n",
    "        p(y|x) = sum_k p(y,k|x) = sum_k [p(y|x,k) p(k|x)]\n",
    "        - p(k|x) is the weights for the k-th component\n",
    "            p(k|x) ~ p(x|k) p(k)\n",
    "        - Each component p(y|x,k) is a Gaussian\n",
    "        \"\"\"\n",
    "        # calculate p(k|x)\n",
    "        ps_cond = np.array([d_x.pdf(x) for d_x in self.dists_x]) * self.ps\n",
    "        ps_cond /= ps_cond.sum()\n",
    "\n",
    "        # calculate p(y|x,k)\n",
    "        means_cond = [\n",
    "            self.dists_y[k].mean\n",
    "            + self.dists[k].cov[self.y_slice, self.x_slice]\n",
    "            @ np.linalg.solve(self.dists_x[k].cov, x - self.dists_x[k].mean)\n",
    "            for k in range(self.K)\n",
    "        ]\n",
    "        covs_cond = [\n",
    "            self.dists_y[k].cov\n",
    "            - self.dists[k].cov[self.y_slice, self.x_slice]\n",
    "            @ np.linalg.solve(self.dists_x[k].cov, self.dists[k].cov[self.x_slice, self.y_slice])\n",
    "            for k in range(self.K)\n",
    "        ]\n",
    "        return GMM(means_cond, covs_cond, ps_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA = 0.9\n",
    "PHI = 0.7\n",
    "\n",
    "# ALPHA = 0.1\n",
    "# PHI = 0.1\n",
    "\n",
    "Y1, Y2 = np.meshgrid(np.linspace(-6, 11, 100), np.linspace(-5, 6, 100))\n",
    "\n",
    "def plot_gmm_cond(\n",
    "    ax: plt.Axes, x: np.ndarray,\n",
    "    alpha: float = ALPHA, phi: float = PHI\n",
    ") -> None:\n",
    "    gmm = GMM(\n",
    "        *synthetic.create_gmm(alpha=alpha, phi=phi),\n",
    "        x_slice=slice(2, None), y_slice=slice(0, 2)\n",
    "    )\n",
    "    gmm_cond = gmm.cond_on_x(x)\n",
    "\n",
    "    # Option 1: contour plot the PDF\n",
    "    pdf = gmm_cond.pdf(np.stack([Y1, Y2], axis=-1))\n",
    "    ax.contourf(Y1, Y2, pdf, levels=100, cmap=plt.cm.magma_r)\n",
    "\n",
    "    # Option 2: draw samples, then use seaborn KDE plot\n",
    "    # samples = gmm_cond.sample(size=5000)\n",
    "    # sns.kdeplot(x=samples[:, 0], y=samples[:, 1], fill=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search over alphas & phis to match Chenreddy paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.01, 0.05, 0.1, 0.5, 0.9, 1, 5, 10]\n",
    "phis = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,0.8,0.9]\n",
    "\n",
    "fig, axs = plt.subplots(len(alphas), len(phis), figsize=(20, 20), tight_layout=True)\n",
    "\n",
    "for r, alpha in enumerate(alphas):\n",
    "    for c, phi in enumerate(phis):\n",
    "        ax = axs[r, c]\n",
    "\n",
    "        # x = np.array([2.5, -0.2])\n",
    "        # x = np.array([-2.6, 0.5])\n",
    "        x = np.array([2.7, 1.9])\n",
    "        plot_gmm_cond(ax, x, alpha=alpha, phi=phi)\n",
    "\n",
    "        if r == 0 or c == 0:\n",
    "            ax.set_title(f\"alpha={alpha}, phi={phi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a random selection of conditional distributions from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=0, alpha=ALPHA, phi=PHI)\n",
    "ds = loaders['test'].dataset\n",
    "np.random.seed(2)\n",
    "idxs = np.sort(np.random.choice(len(ds), size=100, replace=False))\n",
    "\n",
    "fig, axs = plt.subplots(10, 10, figsize=(20, 20), tight_layout=True)\n",
    "for i, ax in zip(idxs, axs.flat):\n",
    "    x = ds[i][0].numpy()\n",
    "    y = ds[i][1].numpy() * y_std + y_mean\n",
    "    plot_gmm_cond(ax, x, alpha=ALPHA, phi=PHI)\n",
    "    ax.scatter(y[0], y[1], color='green', s=20)\n",
    "    ax.set(title=f'index {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot sublevel set of PICNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_picnn_contour(\n",
    "    ckpt_path: str, hidden_dim: int, alpha: float, seed: int, x: np.ndarray, label: str, ax: plt.Axes,\n",
    "    color: Any, y: np.ndarray | None = None\n",
    ") -> None:\n",
    "    from models.picnn import PICNN, conformal_q\n",
    "    from portfolio.problems import PortfolioProblemPICNN\n",
    "\n",
    "    model = PICNN(input_dim=2, y_dim=2, hidden_dim=hidden_dim, n_layers=2, y_in_output_layer=False)\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "\n",
    "    loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=seed, alpha=ALPHA, phi=PHI)\n",
    "    prob = PortfolioProblemPICNN(N=2, L=2, d=hidden_dim, y_mean=y_mean, y_std=y_std)\n",
    "\n",
    "    q = conformal_q(model, loaders['calib'], alpha=alpha).item()\n",
    "\n",
    "    thetas = np.linspace(0, 2*np.pi, num=100, endpoint=False)\n",
    "    cs = np.stack([np.sin(thetas), np.cos(thetas)], axis=1)\n",
    "    ys = [\n",
    "        prob.solve_primal_max(x, model, q=q, c=c)\n",
    "        for c in cs\n",
    "    ]\n",
    "    ys.append(ys[0])  # close the polygon\n",
    "    ys = np.stack(ys)\n",
    "\n",
    "    ys = ys * y_std + y_mean\n",
    "    ax.plot(ys[:, 0], ys[:, 1], label=label, ls='--', lw=2, color=color)\n",
    "\n",
    "    if y is not None:\n",
    "        prob.solve(x, model, q=q)\n",
    "        task_loss = prob.task_loss_np(y, is_standardized=True)\n",
    "\n",
    "        z = prob.primal_vars['z'].value\n",
    "        # ax.plot([0, 3*z[0]], [0, 3*z[1]], label=r'$z^\\star$', color=color)\n",
    "        ax.arrow(0, 0, 3*z[0], 3*z[1], width=0.15, label=r'$z^\\star$', color=color)\n",
    "        # ax.quiver(0, 0, z[0], z[1], scale=5, width=0.015, label=r'$z^\\star$', color=color)\n",
    "    else:\n",
    "        task_loss = None\n",
    "\n",
    "    return task_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sublevel set at a specific `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "\n",
    "x = np.array([2.7, 1.9])\n",
    "plot_gmm_cond(ax, x)\n",
    "\n",
    "plot_picnn_contour(\n",
    "    ckpt_path='out/portfolio_syn_picnn_d128/e2e_finetune_a0.10_L2_d128_lr0.005_reg0.001_seed0.pt',\n",
    "    hidden_dim=128, alpha=0.1, seed=0, x=x, label='e2e', ax=ax,\n",
    "    color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "\n",
    "plot_picnn_contour(\n",
    "    ckpt_path='out/portfolio_syn_picnn_d128/eto_L2_d128_lr0.01_reg0.001_seed0.pt',\n",
    "    hidden_dim=128, alpha=0.1, seed=0, x=x, label='eto', ax=ax,\n",
    "    color=plt.cm.tab10.colors[1]\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot PICNN sublevel sets for different alphas at a test set `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3), tight_layout=True)\n",
    "\n",
    "seed = 2\n",
    "loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=seed, alpha=ALPHA, phi=PHI)\n",
    "ds = loaders['test'].dataset\n",
    "\n",
    "#  192, 280, 931\n",
    "# 305 is inverted egg\n",
    "\n",
    "x = ds[305][0].numpy()\n",
    "y = ds[305][1].numpy()\n",
    "\n",
    "y_unstandardized = y * y_std + y_mean\n",
    "\n",
    "for ax, alpha in zip(axs, (0.01, 0.05, 0.1, 0.2)):\n",
    "\n",
    "    plot_gmm_cond(ax, x, alpha=ALPHA, phi=PHI)\n",
    "\n",
    "    eto_task_loss = plot_picnn_contour(\n",
    "        ckpt_path='out/portfolio_syn_picnn_d128/eto_L2_d128_lr0.01_reg0.001_seed0.pt',\n",
    "        hidden_dim=128, alpha=alpha, seed=seed, x=x, y=y, label='eto', ax=ax,\n",
    "        color=plt.cm.tab10.colors[1]\n",
    "    )\n",
    "\n",
    "    e2e_task_loss = plot_picnn_contour(\n",
    "        ckpt_path=f'out/portfolio_syn_picnn_d128/e2e_finetune_a{alpha:.2f}_L2_d128_lr0.005_reg0.001_seed0.pt',\n",
    "        hidden_dim=128, alpha=alpha, seed=seed, x=x, y=y, label='e2e', ax=ax,\n",
    "        color=plt.cm.tab10.colors[0]\n",
    "    )\n",
    "\n",
    "    # un-standardize the true y before plotting\n",
    "    ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "\n",
    "    ax.legend()\n",
    "    ax.set(title=f'alpha {alpha}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot box uncertainty from quantile regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from matplotlib.legend_handler import HandlerPatch\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "def make_legend_arrow(legend, orig_handle,\n",
    "                      xdescent, ydescent,\n",
    "                      width, height, fontsize):\n",
    "    p = mpatches.FancyArrow(0, 0.5*height, width, 0, length_includes_head=True, head_width=0.75*height )\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(\n",
    "    ckpt_path: str, alpha: float, seed: int, x: np.ndarray, label: str, ax: plt.Axes,\n",
    "    color: Any, y: np.ndarray | None = None\n",
    ") -> None:\n",
    "    from models.quantile import QuantileRegressor, conformal_q\n",
    "    from portfolio.problems import PortfolioProblemBox\n",
    "\n",
    "    model = QuantileRegressor(input_dim=2, y_dim=2)\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=seed, alpha=ALPHA, phi=PHI)\n",
    "    q = conformal_q(model, loaders['calib'], y_dim=2, alpha=alpha).item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_batch = torch.from_numpy(x[None]).to(dtype=torch.float32)\n",
    "        pred = model(x_batch)[0].numpy()\n",
    "\n",
    "    pred_lo = pred[:2] - q\n",
    "    pred_hi = pred[2:] + q\n",
    "\n",
    "    pred_lo_unstd = pred_lo * y_std + y_mean\n",
    "    pred_hi_unstd = pred_hi * y_std + y_mean\n",
    "\n",
    "    box_points = np.array([\n",
    "        pred_lo_unstd,\n",
    "        [pred_lo_unstd[0], pred_hi_unstd[1]],\n",
    "        pred_hi_unstd,\n",
    "        [pred_hi_unstd[0], pred_lo_unstd[1]],\n",
    "        pred_lo_unstd\n",
    "    ])\n",
    "    ax.plot(box_points[:, 0], box_points[:, 1], lw=2, ls='--', label=label, color=color)\n",
    "\n",
    "    if y is not None:\n",
    "        prob = PortfolioProblemBox(N=2, y_mean=y_mean, y_std=y_std)\n",
    "        prob.solve(pred_lo, pred_hi)\n",
    "        task_loss = prob.task_loss_np(y, is_standardized=True)\n",
    "\n",
    "        # label = f'{label}, task loss {task_loss:.2g}'\n",
    "        z = prob.primal_vars['z'].value\n",
    "        # ax.plot([0, 3*z[0]], [0, 3*z[1]], label=r'$z^\\star$', color=color)\n",
    "        ax.arrow(0, 0, 3*z[0], 3*z[1], width=0.15, label=r'$z^\\star$', color=color)\n",
    "        # ax.quiver(0, 0, z[0], z[1], scale=5, width=0.015, label=r'$z^\\star$', color=color)\n",
    "    else:\n",
    "        task_loss = None\n",
    "    \n",
    "    return task_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "\n",
    "loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=0, alpha=ALPHA, phi=PHI)\n",
    "ds = loaders['test'].dataset\n",
    "\n",
    "#  192, 280, 931\n",
    "# 305 is inverted egg\n",
    "\n",
    "x = ds[192][0].numpy()\n",
    "y = ds[192][1].numpy()\n",
    "\n",
    "plot_gmm_cond(ax, x)\n",
    "\n",
    "# SAVED_LR = {0.01: 10**(-1.5), 0.05: 10**(-1.5), 0.1: 1e-2, 0.2: 10**(-2.5)}\n",
    "# SAVED_L2REG = {0.01: 1e-4, 0.05: 1e-4, 0.1: 1e-3, 0.2: 1e-3}\n",
    "\n",
    "plot_box(\n",
    "    ckpt_path='out/portfolio_syn_quantile/eto_a0.10_lr0.01_reg0.001_seed0.pt',\n",
    "    alpha=0.1, seed=0, x=x, y=y, label='e2e', ax=ax, color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "\n",
    "plot_box(\n",
    "    ckpt_path='out/portfolio_syn_quantile/e2e_finetune_a0.10_lr0.0001_reg0.001_seed0.pt',\n",
    "    alpha=0.1, seed=0, x=x, y=y, label='eto', ax=ax, color=plt.cm.tab10.colors[1]\n",
    ")\n",
    "\n",
    "# un-standardize the true y before plotting\n",
    "y_unstandardized = y * y_std + y_mean\n",
    "ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "\n",
    "ax.legend(handler_map={mpatches.FancyArrow: HandlerPatch(patch_func=make_legend_arrow)})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ellipse uncertainty from Gaussian regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_to_ellipse_params(cov, q):\n",
    "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
    "\n",
    "    # Calculate the angle of rotation (in degrees)\n",
    "    # angle = np.degrees(np.arctan2(eigvecs[1, 0], eigvecs[0, 0]))\n",
    "    angle = np.degrees(np.arctan2(eigvecs[1, 1], eigvecs[0, 1]))\n",
    "    \n",
    "    # Calculate the width and height\n",
    "    width = 2 * np.sqrt(q * eigvals[0])\n",
    "    height = 2 * np.sqrt(q * eigvals[1])\n",
    "    return width, height, angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ellipse(\n",
    "    ckpt_path: str, alpha: float, seed: int, x: np.ndarray, label: str, ax: plt.Axes,\n",
    "    color: Any, y: np.ndarray | None = None\n",
    ") -> None:\n",
    "    from models.gaussian import GaussianRegressor, conformal_q\n",
    "    from portfolio.problems import PortfolioProblemEllipsoid\n",
    "\n",
    "    model = GaussianRegressor(input_dim=2, y_dim=2)\n",
    "    model.load_state_dict(torch.load(ckpt_path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=seed, alpha=ALPHA, phi=PHI)\n",
    "    q = conformal_q(model, loaders['calib'], alpha=alpha).item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_batch = torch.from_numpy(x[None]).to(dtype=torch.float32)\n",
    "        loc, scale_tril = model(x_batch)\n",
    "        loc = loc[0].numpy()\n",
    "        scale_tril = scale_tril[0].numpy()\n",
    "\n",
    "    if y is not None:\n",
    "        prob = PortfolioProblemEllipsoid(N=2, y_mean=y_mean, y_std=y_std)\n",
    "        prob.solve(loc, scale_tril * np.sqrt(q))\n",
    "        task_loss = prob.task_loss_np(y, is_standardized=True)\n",
    "\n",
    "        label = f'{label}, task loss {task_loss:.2g}'\n",
    "        z = prob.primal_vars['z'].value\n",
    "        # ax.plot([0, 3*z[0]], [0, 3*z[1]], label=r'$z^\\star$', ls=':', color=color)\n",
    "        ax.arrow(0, 0, 3*z[0], 3*z[1], width=0.15, label=r'$z^\\star$', color=color)\n",
    "        # ax.quiver(0, 0, z[0], z[1], scale=5, width=0.015, label=r'$z^\\star$', color=color)\n",
    "    else:\n",
    "        task_loss = None\n",
    "\n",
    "    # {yhat  :   (yhat - loc).T @ inv(cov) @ (yhat - loc) <= q}\n",
    "    # yhat = (y - y_mean) / y_std = Sinv @ (y - y_mean)\n",
    "    # {y :    (Sinv @ (y - y_mean) - loc).T @ inv(cov) @ (Sinv @ (y - y_mean) - loc) <= q}\n",
    "    # {y :    (y - y_mean - S @ loc).T @ Sinv @ inv(cov) @ Sinv @ (y - y_mean - S @ loc) <= q}\n",
    "    # ellipse with center = (y_mean + S @ loc) and cov = Sinv @ inv(cov) @ Sinv\n",
    "\n",
    "    cov = scale_tril @ scale_tril.T\n",
    "    Sinv = np.diag(1. / y_std)\n",
    "    width, height, angle = gaussian_to_ellipse_params(Sinv @ np.linalg.pinv(cov) @ Sinv, q)\n",
    "    mean = y_mean + loc * y_std\n",
    "\n",
    "    ellipse = Ellipse(mean, width, height, angle=angle, ls='--', lw=2, fill=False, color=color)\n",
    "    ax.add_artist(ellipse)\n",
    "    return task_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "\n",
    "loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=0, alpha=ALPHA, phi=PHI)\n",
    "ds = loaders['test'].dataset\n",
    "\n",
    "#  192, 280, 931\n",
    "# 305 is inverted egg\n",
    "\n",
    "x = ds[192][0].numpy()\n",
    "y = ds[192][1].numpy()\n",
    "\n",
    "plot_gmm_cond(ax, x)\n",
    "\n",
    "# SAVED_LR = {0.01: 10**(-1.5), 0.05: 10**(-1.5), 0.1: 1e-2, 0.2: 10**(-2.5)}\n",
    "# SAVED_L2REG = {0.01: 1e-4, 0.05: 1e-4, 0.1: 1e-3, 0.2: 1e-3}\n",
    "\n",
    "plot_ellipse(\n",
    "    ckpt_path='out/portfolio_syn_gaussian/eto_lr0.000316_reg0.01_seed0.pt',\n",
    "    alpha=0.01, seed=0, x=x, y=y, label='eto', ax=ax, color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "\n",
    "# plot_box(\n",
    "#     ckpt_path='out/portfolio_syn_quantile/e2e_finetune_a0.10_lr0.0001_reg0.001_seed0.pt',\n",
    "#     alpha=0.1, seed=0, x=x, y=y, label='eto', ax=ax, color=plt.cm.tab10.colors[1]\n",
    "# )\n",
    "\n",
    "# un-standardize the true y before plotting\n",
    "y_unstandardized = y * y_std + y_mean\n",
    "ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot box, ellipse, and PICNN in 1 fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(9, 3), sharey=True, tight_layout=True)\n",
    "\n",
    "seed = 2\n",
    "loaders, (y_mean, y_std) = synthetic.get_loaders(batch_size=256, seed=seed, alpha=ALPHA, phi=PHI)\n",
    "ds = loaders['test'].dataset\n",
    "\n",
    "#  192, 280, 931\n",
    "# 305 is inverted egg\n",
    "\n",
    "x = ds[192][0].numpy()\n",
    "y = ds[192][1].numpy()\n",
    "y_unstandardized = y * y_std + y_mean\n",
    "\n",
    "# box uncertainty\n",
    "ax = axs[0]\n",
    "plot_gmm_cond(ax, x)\n",
    "eto_task_loss = plot_box(\n",
    "    ckpt_path='out/portfolio_syn_quantile/eto_a0.10_lr0.01_reg0.001_seed0.pt',\n",
    "    alpha=0.1, seed=seed, x=x, y=y, label='ETO', ax=ax, color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "e2e_task_loss = plot_box(\n",
    "    ckpt_path='out/portfolio_syn_quantile/e2e_finetune_a0.10_lr0.0001_reg0.001_seed0.pt',\n",
    "    alpha=0.1, seed=seed, x=x, y=y, label='E2E', ax=ax, color=plt.cm.tab10.colors[1]\n",
    ")\n",
    "ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "ax.set(title=f'Box\\nETO task loss {eto_task_loss:.2f}\\nE2E task loss {e2e_task_loss:.2f}')\n",
    "\n",
    "# ellipse uncertainty\n",
    "ax = axs[1]\n",
    "plot_gmm_cond(ax, x)\n",
    "eto_task_loss = plot_ellipse(\n",
    "    ckpt_path='out/portfolio_syn_gaussian/eto_lr0.000316_reg0.01_seed0.pt',\n",
    "    alpha=0.1, seed=seed, x=x, y=y, label='ETO', ax=ax, color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "e2e_task_loss = plot_ellipse(\n",
    "    ckpt_path='out/portfolio_syn_gaussian/e2e_finetune_a0.01_lr0.001_reg0.01_seed0.pt',\n",
    "    alpha=0.1, seed=seed, x=x, y=y, label='E2E', ax=ax, color=plt.cm.tab10.colors[1]\n",
    ")\n",
    "ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "ax.set(title=f'Ellipse\\nETO task loss {eto_task_loss:.2f}\\nE2E task loss {e2e_task_loss:.2f}')\n",
    "\n",
    "ax = axs[2]\n",
    "plot_gmm_cond(ax, x)\n",
    "alpha = 0.1\n",
    "eto_task_loss = plot_picnn_contour(\n",
    "    ckpt_path='out/portfolio_syn_picnn_d128/eto_L2_d128_lr0.01_reg0.001_seed0.pt',\n",
    "    hidden_dim=128, alpha=alpha, seed=seed, x=x, y=y, label='ETO', ax=ax,\n",
    "    color=plt.cm.tab10.colors[1]\n",
    ")\n",
    "e2e_task_loss = plot_picnn_contour(\n",
    "    ckpt_path=f'out/portfolio_syn_picnn_d128/e2e_finetune_a{alpha:.2f}_L2_d128_lr0.005_reg0.001_seed0.pt',\n",
    "    hidden_dim=128, alpha=alpha, seed=seed, x=x, y=y, label='E2E', ax=ax,\n",
    "    color=plt.cm.tab10.colors[0]\n",
    ")\n",
    "ax.scatter(y_unstandardized[0], y_unstandardized[1], color='green', s=20, label='true y')\n",
    "ax.set(title=f'PICNN\\nETO task loss {eto_task_loss:.2f}\\nE2E task loss {e2e_task_loss:.2f}')\n",
    "\n",
    "ax.legend(\n",
    "    handler_map={mpatches.FancyArrow: HandlerPatch(patch_func=make_legend_arrow)},\n",
    "    bbox_to_anchor=(1.05, 1), loc='upper left'\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dauq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
